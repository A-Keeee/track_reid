# REID+å§¿æ€+å‰10sæ— é‡å¤ç‰¹å¾+gRPCé€šä¿¡
# 
# æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ - å•ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ
# 
import cv2
import numpy as np
from ultralytics import YOLO
from collections import deque, defaultdict
import time
import math
import depthai as dai
import random
import heapq
import sys
import os
import pickle
import threading
import queue
import grpc
import argparse

# --- [ä¿®æ”¹] ReID ç›¸å…³å¯¼å…¥ ---
try:
    import torch
    import torch.nn.functional as F
    from torchvision.transforms import ToTensor
    from PIL import Image
    # å¯¼å…¥æ–°çš„ReIDåº“ç»„ä»¶
    from reid.config import cfg as reidCfg
    from reid.modeling import build_model
    from reid.data.transforms import build_transforms
    print("PyTorch å’Œ ReID åº“å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"è­¦å‘Š: å¯¼å…¥å¤±è´¥ ({e})ï¼ŒReIDåŠŸèƒ½å°†å—é™")
    print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… PyTorch å’Œ fast-reid åº“")
    torch = None

# å¯¼å…¥ç”Ÿæˆçš„gRPCæ¨¡å—
try:
    import tracking_pb2
    import tracking_pb2_grpc
except ImportError:
    print("è­¦å‘Š: æœªæ‰¾åˆ°gRPCæ¨¡å—ï¼ŒgRPCé€šä¿¡åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("è¯·è¿è¡Œ: python -m grpc_tools.protoc --python_out=. --grpc_python_out=. --proto_path=. tracking.proto")
    tracking_pb2 = None
    tracking_pb2_grpc = None

# å…¨å±€å˜é‡ï¼šç‰¹å¾å­˜å‚¨è·¯å¾„
FEATURE_STORAGE_PATH = "target_features.pkl"

# å…¨å±€å˜é‡ï¼šReIDå¤„ç†å™¨
reid_handler = None

# ç¡®ä¿æ¸…ç†æ—§ç‰¹å¾æ–‡ä»¶
if os.path.exists(FEATURE_STORAGE_PATH):
    os.remove(FEATURE_STORAGE_PATH)
    print(f"å·²æ¸…ç†æ—§ç‰¹å¾æ–‡ä»¶: {FEATURE_STORAGE_PATH}")

# --- [æ–°å¢] åŸºäº reid åº“çš„ç‰¹å¾å¤„ç†å™¨ ---
class ReIDHandler:
    def __init__(self, model_path): # <-- ä¿®æ”¹ï¼šç§»é™¤ config_file å‚æ•°
        if torch is None:
            self.model = None
            print("é”™è¯¯: PyTorchæœªå®‰è£…ï¼Œæ— æ³•åˆå§‹åŒ–ReIDå¤„ç†å™¨")
            return

        try:
            # --- [ä¿®æ”¹] ä½¿ç”¨å¯¼å…¥çš„ reidCfg, ä¸å†ä»æ–‡ä»¶åŠ è½½ ---
            reidCfg.MODEL.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
            # DEVICE_IDåœ¨defaults.pyä¸­æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä¿æŒä¸€è‡´
            reidCfg.MODEL.DEVICE_ID = '0'
            
            # ä½¿ç”¨ reidCfg ä¸­çš„é…ç½®æ„å»ºæ¨¡å‹, num_classes å‚è€ƒ reid_depthai_oak.py
            self.model = build_model(reidCfg, num_classes=1501) 
            self.model.load_param(model_path) # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æƒé‡è·¯å¾„
            self.model.to(reidCfg.MODEL.DEVICE).eval()
            
            self.transforms = build_transforms(reidCfg) # <-- ä¿®æ”¹ï¼šç§»é™¤ is_train=False å‚æ•°
            self.device = reidCfg.MODEL.DEVICE
            self.dist_thresh = 1.15 # æ¬§æ°è·ç¦»é˜ˆå€¼
            print(f"ReIDæ¨¡å‹å·²æˆåŠŸåŠ è½½åˆ° {self.device}")

        except Exception as e:
            self.model = None
            print(f"åˆå§‹åŒ–ReIDå¤„ç†å™¨æ—¶å‡ºé”™: {e}")

    def extract_features(self, image_bgr):
        """ ä½¿ç”¨æ–°çš„ReIDæ¨¡å‹æå–ç‰¹å¾ """
        if self.model:
            try:
                # é¢„å¤„ç†: BGR -> RGB -> PIL -> Tensor
                pil_img = Image.fromarray(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))
                input_tensor = self.transforms(pil_img).unsqueeze(0).to(self.device)

                # æ¨ç†
                with torch.no_grad():
                    features = self.model(input_tensor)
                
                # åå¤„ç†ï¼šL2å½’ä¸€åŒ–
                features = F.normalize(features, dim=1, p=2)
                return features.cpu() # è¿”å›Tensorï¼Œä¾¿äºåç»­è®¡ç®—
            except Exception as e:
                print(f"ReIDç‰¹å¾æå–å¤±è´¥: {e}")
                return self.fallback_feature_extractor(image_bgr)
        else:
            return self.fallback_feature_extractor(image_bgr)
    
    def compute_distance(self, feature1_tensor, feature2_tensor):
        """ è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡ä¹‹é—´çš„æ¬§æ°è·ç¦» """
        distmat = torch.pow(feature1_tensor, 2).sum(dim=1, keepdim=True) + \
                  torch.pow(feature2_tensor, 2).sum(dim=1, keepdim=True).t()
        # ä½¿ç”¨æ–°çš„ã€åŸºäºå…³é”®å­—å‚æ•°çš„ç­¾åæ¥è°ƒç”¨ addmm_
        distmat.addmm_(feature1_tensor, feature2_tensor.t(), beta=1, alpha=-2)
        return distmat.squeeze().item()

    def fallback_feature_extractor(self, image):
        """ å¤‡ç”¨ç‰¹å¾æå–å™¨ï¼ˆé¢œè‰²ç›´æ–¹å›¾ï¼‰ """
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        hist = cv2.calcHist([hsv], [0, 1], None, [12, 12], [0, 180, 0, 256])
        cv2.normalize(hist, hist)
        # è¿”å›ä¸€ä¸ªä¼ªTensorä»¥ä¾¿åç»­å¤„ç†
        return torch.from_numpy(hist.flatten()).unsqueeze(0)


# å§¿æ€ç‰¹å¾æå–ä¸ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆæ¥è‡ªtrack_pose.pyï¼‰
def extract_pose_features(keypoints):
    """æå–è¯¦ç»†çš„å§¿æ€ç‰¹å¾ç”¨äºåŒ¹é…"""
    if keypoints is None or len(keypoints) < 17:
        return None
    
    kpts = keypoints.copy()
    valid_mask = (kpts[:, 0] > 0) & (kpts[:, 1] > 0)
    valid_kpts = kpts[valid_mask]
    
    if len(valid_kpts) < 5:
        return None
    
    left_shoulder, right_shoulder = 5, 6
    left_hip, right_hip = 11, 12
    
    center_points = []
    if valid_mask[left_shoulder] and valid_mask[right_shoulder]:
        center_points.extend([kpts[left_shoulder], kpts[right_shoulder]])
    if valid_mask[left_hip] and valid_mask[right_hip]:
        center_points.extend([kpts[left_hip], kpts[right_hip]])
    
    center = np.mean(center_points, axis=0) if len(center_points) > 0 else np.mean(valid_kpts, axis=0)
    
    distances = np.linalg.norm(valid_kpts - center, axis=1)
    scale = np.max(distances) if len(distances) > 0 and np.max(distances) > 0 else 1.0
    
    features = []
    for i in range(17):
        if valid_mask[i]:
            features.extend(((kpts[i] - center) / scale).tolist())
        else:
            features.extend([0.0, 0.0])
            
    return np.array(features)

def pose_similarity(feat1, feat2):
    """è®¡ç®—å§¿æ€ç‰¹å¾ç›¸ä¼¼åº¦"""
    if feat1 is None or feat2 is None:
        return 0.0
    
    norm1 = np.linalg.norm(feat1)
    norm2 = np.linalg.norm(feat2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
        
    cos_sim = np.dot(feat1, feat2) / (norm1 * norm2)
    return max(0.0, min(1.0, cos_sim))

def draw_pose_keypoints(img, keypoints, color=(0, 255, 255)):
    """ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹å’Œéª¨æ¶è¿æ¥"""
    if keypoints is None or len(keypoints) < 17:
        return img
    
    # COCOæ ¼å¼17ä¸ªå…³é”®ç‚¹çš„è¿æ¥å…³ç³»
    skeleton = [
        [16, 14], [14, 12], [17, 15], [15, 13], [12, 13],
        [6, 12], [7, 13], [6, 7], [6, 8], [7, 9],
        [8, 10], [9, 11], [2, 3], [1, 2], [1, 3],
        [2, 4], [3, 5], [4, 6], [5, 7]
    ]
    
    # ç»˜åˆ¶å…³é”®ç‚¹
    for i, (x, y) in enumerate(keypoints):
        if x > 0 and y > 0:
            cv2.circle(img, (int(x), int(y)), 3, color, -1)
    
    # ç»˜åˆ¶éª¨æ¶è¿æ¥
    for connection in skeleton:
        pt1_idx, pt2_idx = connection[0] - 1, connection[1] - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        if (pt1_idx < len(keypoints) and pt2_idx < len(keypoints) and 
            keypoints[pt1_idx][0] > 0 and keypoints[pt1_idx][1] > 0 and
            keypoints[pt2_idx][0] > 0 and keypoints[pt2_idx][1] > 0):
            pt1 = (int(keypoints[pt1_idx][0]), int(keypoints[pt1_idx][1]))
            pt2 = (int(keypoints[pt2_idx][0]), int(keypoints[pt2_idx][1]))
            cv2.line(img, pt1, pt2, color, 2)
    
    return img

# gRPCå®¢æˆ·ç«¯ç±»
class TrackingGRPCClient:
    def __init__(self, server_address='localhost:50051'):
        self.server_address = server_address
        self.channel = None
        self.stub = None
        self.connected = False
        self.last_coordinate_time = 0
        self.coordinate_interval = 0.1  # åæ ‡å‘é€é—´éš”ï¼ˆç§’ï¼‰
        self.coordinate_queue = queue.Queue(maxsize=100)
        self.stream_thread = None
        self.streaming = False
        
    def connect(self):
        """è¿æ¥åˆ°gRPCæœåŠ¡å™¨"""
        if tracking_pb2 is None or tracking_pb2_grpc is None:
            print("gRPCæ¨¡å—æœªå¯¼å…¥ï¼Œè·³è¿‡è¿æ¥")
            return False
            
        try:
            self.channel = grpc.insecure_channel(self.server_address)
            # æµ‹è¯•è¿æ¥
            grpc.channel_ready_future(self.channel).result(timeout=5)
            self.stub = tracking_pb2_grpc.TrackingServiceStub(self.channel)
            self.connected = True
            print(f"âœ… gRPCå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ: {self.server_address}")
            
            # å¯åŠ¨åæ ‡æµä¼ è¾“
            self.start_coordinate_stream()
            return True
            
        except grpc.RpcError as e:
            print(f"âŒ gRPC RPCé”™è¯¯: {e.code()}: {e.details()}")
            self.connected = False
            return False
        except Exception as e:
            print(f"âŒ gRPCè¿æ¥å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            self.connected = False
            return False
    
    def start_coordinate_stream(self):
        """å¯åŠ¨åæ ‡æµä¼ è¾“"""
        if not self.connected:
            return
            
        def coordinate_generator():
            """åæ ‡æ•°æ®ç”Ÿæˆå™¨"""
            while self.streaming:
                try:
                    coordinate = self.coordinate_queue.get(timeout=1.0)
                    yield coordinate
                except queue.Empty:
                    # å‘é€å¿ƒè·³ï¼ˆåªåŒ…å«x, y, zï¼‰
                    yield tracking_pb2.CoordinateData(
                        x=0.0, y=0.0, z=0.0
                    )
        
        def stream_worker():
            """æµä¼ è¾“å·¥ä½œçº¿ç¨‹"""
            try:
                self.streaming = True
                response = self.stub.SendCoordinates(coordinate_generator())
                print(f"åæ ‡æµä¼ è¾“ç»“æœ: {response.message}")
            except Exception as e:
                print(f"âŒ åæ ‡æµä¼ è¾“å¤±è´¥: {e}")
            finally:
                self.streaming = False
        
        self.stream_thread = threading.Thread(target=stream_worker)
        self.stream_thread.daemon = True
        self.stream_thread.start()
        print("ğŸ“¡ åæ ‡æµä¼ è¾“å·²å¯åŠ¨")
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        self.streaming = False
        if self.stream_thread:
            self.stream_thread.join(timeout=2)
            
        if self.channel:
            try:
                self.channel.close()
                self.connected = False
                print("gRPCå®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥")
            except:
                pass
    
    def send_target_coordinates(self, target_state):
        """å‘é€ç›®æ ‡åæ ‡åˆ°æœåŠ¡å™¨"""
        if not self.connected or tracking_pb2 is None or not self.streaming:
            return False
            
        current_time = time.time()
        if current_time - self.last_coordinate_time < self.coordinate_interval:
            return True  # è·³è¿‡å‘é€ï¼Œé¿å…è¿‡äºé¢‘ç¹
            
        try:
            if target_state and target_state.active and target_state.world_position:
                X, Y, Z = target_state.world_position
                
                # åˆ›å»ºåæ ‡æ¶ˆæ¯ï¼ˆåªåŒ…å«x, y, zï¼‰
                coordinate_msg = tracking_pb2.CoordinateData(
                    x=float(X),
                    y=float(Y), 
                    z=float(Z)
                )
                
                # å°†åæ ‡æ·»åŠ åˆ°é˜Ÿåˆ—
                try:
                    self.coordinate_queue.put_nowait(coordinate_msg)
                    self.last_coordinate_time = current_time
                    return True
                except queue.Full:
                    # é˜Ÿåˆ—æ»¡æ—¶ç§»é™¤æœ€æ—§çš„æ•°æ®
                    try:
                        self.coordinate_queue.get_nowait()
                        self.coordinate_queue.put_nowait(coordinate_msg)
                        self.last_coordinate_time = current_time
                        return True
                    except queue.Empty:
                        pass
                
            else:
                # å‘é€æ— æ´»è·ƒç›®æ ‡çš„å¿ƒè·³ï¼ˆåªåŒ…å«x, y, zï¼‰
                coordinate_msg = tracking_pb2.CoordinateData(
                    x=0.0, y=0.0, z=0.0
                )
                
                try:
                    self.coordinate_queue.put_nowait(coordinate_msg)
                    self.last_coordinate_time = current_time
                    return True
                except queue.Full:
                    return True  # å¿ƒè·³æ•°æ®å¯ä»¥ä¸¢å¼ƒ
                
        except Exception as e:
            print(f"âŒ å‘é€åæ ‡å¤±è´¥: {e}")
            return False
    
    def send_tracking_status(self, is_active, target_id=0, tracking_time=0.0):
        """å‘é€è·Ÿè¸ªçŠ¶æ€"""
        if not self.connected or tracking_pb2 is None:
            return False
            
        try:
            status_msg = tracking_pb2.TrackingStatus(
                is_active=is_active,
                target_id=target_id,
                tracking_time=tracking_time,
                timestamp=time.time()
            )
            
            # è¿™é‡Œå¯ä»¥å‘é€çŠ¶æ€åˆ°æœåŠ¡å™¨
            # response = self.stub.SendTrackingStatus(status_msg)
            return True
            
        except Exception as e:
            print(f"âŒ å‘é€è·Ÿè¸ªçŠ¶æ€å¤±è´¥: {e}")
            return False
    
    def get_follow_commands(self):
        """è·å–è·ŸéšæŒ‡ä»¤ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
        if not self.connected or tracking_pb2 is None:
            return None
            
        try:
            # ä»æœåŠ¡å™¨è·å–è·Ÿè¸ªçŠ¶æ€æŒ‡ä»¤
            request = tracking_pb2.Empty()
            response = self.stub.GetTrackingStatus(request)
            
            # è½¬æ¢ä¸ºå‘½ä»¤æ ¼å¼
            if response.is_active and response.target_id > 0:
                return [{'action': 'follow', 'target_id': response.target_id}]
            elif not response.is_active:
                return [{'action': 'stop_follow'}]
            else:
                return None
            
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…è¿‡å¤šæ—¥å¿—
            return None


# åˆå§‹åŒ–gRPCå®¢æˆ·ç«¯
grpc_client = TrackingGRPCClient()


# ç‰¹å¾å­˜å‚¨ç®¡ç†å™¨
class FeatureStorage:
    def __init__(self, file_path=FEATURE_STORAGE_PATH):
        self.file_path = file_path
        self.features = {}
        # ä¸åŠ è½½æ—§ç‰¹å¾ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œä»é›¶å¼€å§‹

    def save_features(self):
        """ä¿å­˜ç‰¹å¾åˆ°æ–‡ä»¶"""
        try:
            with open(self.file_path, 'wb') as f:
                pickle.dump(self.features, f)
            print(f"å·²ä¿å­˜{len(self.features)}ä¸ªç›®æ ‡çš„ç‰¹å¾åˆ°{self.file_path}")
        except Exception as e:
            print(f"ä¿å­˜ç‰¹å¾å¤±è´¥: {e}")

    def add_feature(self, target_id, feature):
        """æç®€å•ç›®æ ‡æ¨¡å¼ï¼šåªä¿ç•™å”¯ä¸€ç›®æ ‡çš„ç‰¹å¾"""
        self.features.clear()
        self.features[target_id] = [feature]

    def get_features(self, target_id):
        """è·å–ç›®æ ‡çš„æ‰€æœ‰ç‰¹å¾"""
        return self.features.get(target_id, [])

    def find_best_match(self, candidate_feature, threshold=0.6):
        """åœ¨æ‰€æœ‰ä¿å­˜çš„ç‰¹å¾ä¸­å¯»æ‰¾æœ€ä½³åŒ¹é…"""
        best_match_id = None
        max_similarity = 0.0

        for target_id, features in self.features.items():
            for feature in features:
                try:
                    similarity = np.dot(feature.flatten(), candidate_feature.flatten()) / (
                            np.linalg.norm(feature) * np.linalg.norm(candidate_feature) + 1e-10)
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_match_id = target_id
                except:
                    continue

        if max_similarity > threshold:
            return best_match_id, max_similarity
        return None, max_similarity

    def clear_all_features(self):
        """æ¸…ç†æ‰€æœ‰ç‰¹å¾"""
        self.features.clear()
        print("ğŸ§¹ å·²æ¸…ç†æ‰€æœ‰ç‰¹å¾æ•°æ®")
        
        # åŒæ—¶åˆ é™¤ç‰¹å¾æ–‡ä»¶
        if os.path.exists(self.file_path):
            try:
                os.remove(self.file_path)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ç‰¹å¾æ–‡ä»¶: {self.file_path}")
            except Exception as e:
                print(f"åˆ é™¤ç‰¹å¾æ–‡ä»¶å¤±è´¥: {e}")

    def reset_features(self):
        """é‡ç½®ç‰¹å¾å­˜å‚¨ï¼ˆåˆ«åæ–¹æ³•ï¼‰"""
        self.clear_all_features()


# åˆå§‹åŒ–ç‰¹å¾å­˜å‚¨å™¨
feature_storage = FeatureStorage()


# åˆå§‹åŒ–OAKç›¸æœºç®¡é“
def create_pipeline():
    pipeline = dai.Pipeline()
    cam_rgb = pipeline.create(dai.node.ColorCamera)
    # ä½¿ç”¨æ–°çš„APIæ›¿æ¢å·²å¼ƒç”¨çš„è®¾ç½®
    cam_rgb.setBoardSocket(dai.CameraBoardSocket.CAM_A)
    cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)
    cam_rgb.setPreviewSize(640, 480)
    cam_rgb.setInterleaved(False)
    cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)
    cam_rgb.setFps(45)

    mono_left = pipeline.create(dai.node.MonoCamera)
    mono_right = pipeline.create(dai.node.MonoCamera)
    # ä½¿ç”¨æ–°çš„APIæ›¿æ¢å·²å¼ƒç”¨çš„è®¾ç½®
    mono_left.setBoardSocket(dai.CameraBoardSocket.CAM_B)
    mono_right.setBoardSocket(dai.CameraBoardSocket.CAM_C)
    mono_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
    mono_right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)

    stereo = pipeline.create(dai.node.StereoDepth)
    # ä½¿ç”¨æ–°çš„APIæ›¿æ¢å·²å¼ƒç”¨çš„è®¾ç½®
    stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
    stereo.setDepthAlign(dai.CameraBoardSocket.CAM_A)
    stereo.setOutputSize(mono_left.getResolutionWidth(), mono_left.getResolutionHeight())
    stereo.setLeftRightCheck(True)
    stereo.setExtendedDisparity(False)
    stereo.setSubpixel(False)

    mono_left.out.link(stereo.left)
    mono_right.out.link(stereo.right)

    xout_depth = pipeline.create(dai.node.XLinkOut)
    xout_depth.setStreamName("depth")
    xout_rgb = pipeline.create(dai.node.XLinkOut)
    xout_rgb.setStreamName("rgb")
    cam_rgb.preview.link(xout_rgb.input)
    stereo.depth.link(xout_depth.input)

    return pipeline


# ç›¸æœºè¿æ¥ç®¡ç†å™¨
class CameraManager:
    def __init__(self, max_retries=5, retry_delay=3):
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.device = None
        self.pipeline = None

    def connect_camera(self):
        """å°è¯•è¿æ¥ç›¸æœºï¼Œå¤±è´¥æ—¶é‡è¯•"""
        for attempt in range(self.max_retries):
            try:
                print(f"å°è¯•è¿æ¥OAKç›¸æœº... (ç¬¬ {attempt + 1}/{self.max_retries} æ¬¡)")
                
                # åˆ›å»ºç®¡é“
                self.pipeline = create_pipeline()
                
                # å°è¯•è¿æ¥è®¾å¤‡
                self.device = dai.Device(self.pipeline)
                print("OAKç›¸æœºè¿æ¥æˆåŠŸï¼")
                return True
                
            except Exception as e:
                print(f"ç›¸æœºè¿æ¥å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡): {e}")
                
                # æ¸…ç†èµ„æº
                if self.device:
                    try:
                        self.device.close()
                    except:
                        pass
                    self.device = None
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < self.max_retries - 1:
                    print(f"ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                    time.sleep(self.retry_delay)
                else:
                    print("æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†")
                    return False
        
        return False

    def get_device(self):
        """è·å–è®¾å¤‡å®ä¾‹"""
        return self.device

    def close(self):
        """å…³é—­è®¾å¤‡è¿æ¥"""
        if self.device:
            try:
                self.device.close()
            except:
                pass
            self.device = None


# ç›®æ ‡çŠ¶æ€ç±»ï¼ˆå¢å¼ºé²æ£’æ€§å’Œé¢„æµ‹èƒ½åŠ›ï¼‰
class TargetState:
    def __init__(self, target_id):
        self.target_id = target_id
        self.position = None
        self.velocity = (0, 0)
        self.size = None
        self.confidence = 0.0
        self.timestamp = time.time()
        self.last_seen = time.time()
        self.trajectory = deque(maxlen=50)
        self.world_position = None
        self.distance = 0.0
        self.yaw = 0.0
        self.pitch = 0.0
        self.reid_features = deque(maxlen=20)  # å¢åŠ ç‰¹å¾ä¿ç•™æ•°é‡
        self.stable_features = deque(maxlen=5)  # ç¨³å®šç‰¹å¾é›†åˆ
        self.initial_feature = None  # åˆå§‹ç‰¹å¾
        self.lock_strength = 1.0
        self.stability = 0.0
        self.consecutive_frames = 0
        self.last_update_time = time.time()
        self.last_output_time = time.time()
        self.lost_frame_count = 0
        self.kalman = self.init_kalman_filter()
        self.active = True
        self.color = (0, 0, 255)  # ç›®æ ‡é¢œè‰²
        self.pose_landmarks = None  # å­˜å‚¨å§¿æ€å…³é”®ç‚¹
        self.pose_score = 0.0  # å§¿æ€ç½®ä¿¡åº¦
        self.pose_visibility = 0.0  # å§¿æ€å¯è§åº¦
        self.full_body_feature = None  # å…¨èº«ç‰¹å¾
        self.last_feature_save_time = 0  # ä¸Šæ¬¡ä¿å­˜ç‰¹å¾çš„æ—¶é—´
        # æ·»åŠ å§¿æ€ç‰¹å¾ç›¸å…³å±æ€§ï¼ˆæ¥è‡ªtrack_pose.pyï¼‰
        self.pose_features = deque(maxlen=10)  # å§¿æ€ç‰¹å¾å†å²
        self.stable_pose_features = deque(maxlen=3)  # ç¨³å®šå§¿æ€ç‰¹å¾
        self.initial_pose_feature = None  # åˆå§‹å§¿æ€ç‰¹å¾

    def init_kalman_filter(self):
        kalman = cv2.KalmanFilter(6, 2)
        kalman.transitionMatrix = np.array([
            [1, 0, 1, 0, 0.5, 0],
            [0, 1, 0, 1, 0, 0.5],
            [0, 0, 1, 0, 1, 0],
            [0, 0, 0, 1, 0, 1],
            [0, 0, 0, 0, 1, 0],
            [0, 0, 0, 0, 0, 1]
        ], np.float32)
        kalman.measurementMatrix = np.array([
            [1, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0]
        ], np.float32)
        kalman.processNoiseCov = np.eye(6, dtype=np.float32) * 0.01
        kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.1
        kalman.errorCovPost = np.eye(6, dtype=np.float32) * 0.1
        return kalman

    def update_reid_features(self, frame, box, is_full_body=False):
        # é™åˆ¶ç‰¹å¾æ›´æ–°é¢‘ç‡
        current_time = time.time()
        if current_time - self.last_feature_save_time < 0.5:  # æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡
            return
            
        x1, y1, x2, y2 = map(int, box)
        if y1 >= y2 or x1 >= x2 or y1 < 0 or y2 > frame.shape[0] or x1 < 0 or x2 > frame.shape[1]:
            return

        expand = 10
        x1 = max(0, x1 - expand)
        y1 = max(0, y1 - expand)
        x2 = min(frame.shape[1], x2 + expand)
        y2 = min(frame.shape[0], y2 + expand)
        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

        if x1 >= x2 or y1 >= y2:
            return

        target_roi = frame[y1:y2, x1:x2]
        if target_roi.size == 0:
            return

        # --- [ä¿®æ”¹] ä½¿ç”¨æ–°çš„ReIDå¤„ç†å™¨æå–ç‰¹å¾ ---
        try:
            # reid_handler.extract_features ç°åœ¨è¿”å›ä¸€ä¸ªTensor
            feature_tensor = reid_handler.extract_features(target_roi)
            if feature_tensor is None: return

            # ä¿å­˜åˆå§‹ç‰¹å¾
            if self.initial_feature is None:
                self.initial_feature = feature_tensor
                self.stable_features.append(feature_tensor)
                if is_full_body:
                    self.full_body_feature = feature_tensor
                    # æ³¨æ„ï¼šfeature_storageç°åœ¨å­˜å‚¨Tensor
                    feature_storage.add_feature(self.target_id, feature_tensor)

            # åªåœ¨ç›®æ ‡ç¨³å®šæ—¶æ›´æ–°ç‰¹å¾
            if self.stability > 0.6:
                self.reid_features.append(feature_tensor)

                # å½“ç¨³å®šæ€§é«˜æ—¶æ›´æ–°ç¨³å®šç‰¹å¾
                if self.stability > 0.8 and len(self.stable_features) < 5:
                    self.stable_features.append(feature_tensor)

                    if is_full_body and self.full_body_feature is None:
                        self.full_body_feature = feature_tensor
                        feature_storage.add_feature(self.target_id, feature_tensor)
                        
            self.last_feature_save_time = time.time()
        except Exception as e:
            print(f"ReIDç‰¹å¾æ›´æ–°å¤±è´¥ (TargetState): {e}")

    def compare_signature(self, frame, box):
        if not self.reid_features and not self.stable_features and self.full_body_feature is None:
            return 0.0

        x1, y1, x2, y2 = map(int, box)
        if y1 >= y2 or x1 >= x2 or y1 < 0 or y2 > frame.shape[0] or x1 < 0 or x2 > frame.shape[1]:
            return 0.0

        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

        if x1 >= x2 or y1 >= y2:
            return 0.0

        candidate_roi = frame[y1:y2, x1:x2]
        if candidate_roi.size == 0:
            return 0.0

        # --- [ä¿®æ”¹] ä½¿ç”¨æ¬§æ°è·ç¦»è¿›è¡Œæ¯”å¯¹ï¼Œå¹¶è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•° ---
        try:
            candidate_feature = reid_handler.extract_features(candidate_roi)
            if candidate_feature is None: return 0.0

            min_dist = float('inf')

            # æ”¶é›†æ‰€æœ‰å¾…æ¯”è¾ƒçš„ç‰¹å¾
            features_to_compare = []
            if self.full_body_feature is not None:
                features_to_compare.append(self.full_body_feature)
            if self.initial_feature is not None:
                features_to_compare.append(self.initial_feature)
            features_to_compare.extend(self.stable_features)
            features_to_compare.extend(self.reid_features)

            if not features_to_compare:
                return 0.0
            
            # å°†æ‰€æœ‰åº“ç‰¹å¾åˆå¹¶ä¸ºä¸€ä¸ªTensorè¿›è¡Œæ‰¹é‡è®¡ç®—
            gallery_features = torch.cat(features_to_compare, dim=0)

            # è®¡ç®—å€™é€‰è€…ä¸åº“ä¸­æ‰€æœ‰ç‰¹å¾çš„è·ç¦»
            distmat = torch.pow(candidate_feature, 2).sum(dim=1, keepdim=True).expand(1, len(gallery_features)) + \
                      torch.pow(gallery_features, 2).sum(dim=1, keepdim=True).expand(len(gallery_features), 1).t()
            
            # ä½¿ç”¨æ–°çš„ã€åŸºäºå…³é”®å­—å‚æ•°çš„ç­¾åæ¥è°ƒç”¨ addmm_
            distmat.addmm_(candidate_feature, gallery_features.t(), beta=1, alpha=-2)
            
            # æ‰¾åˆ°æœ€å°è·ç¦»
            min_dist = torch.min(distmat).item()

        except Exception as e:
            print(f"ç‰¹å¾æ¯”è¾ƒå¤±è´¥: {e}")
            return 0.0

        # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•° (0åˆ°1ä¹‹é—´ï¼Œè¶Šé«˜è¶Šå¥½)
        similarity = max(0.0, 1.0 - (min_dist / reid_handler.dist_thresh))
        
        return similarity

    def update_pose(self, keypoints, visibility, score):
        """æ›´æ–°ç›®æ ‡çš„å§¿æ€ä¿¡æ¯ï¼ˆåŸºäºYOLOå…³é”®ç‚¹ï¼‰"""
        self.pose_landmarks = keypoints  # ç°åœ¨å­˜å‚¨YOLOå…³é”®ç‚¹æ ¼å¼ (17, 2)
        self.pose_score = score
        self.pose_visibility = visibility

        # å¦‚æœå§¿æ€ç½®ä¿¡åº¦é«˜ï¼Œå¢åŠ é”å®šå¼ºåº¦
        if score > 0.7:
            self.lock_strength = min(1.0, self.lock_strength + 0.05)
        elif score < 0.3:
            self.lock_strength = max(0.3, self.lock_strength - 0.05)

    def update_pose_features(self, keypoints):
        """æ›´æ–°å§¿æ€ç‰¹å¾ï¼ˆæ¥è‡ªtrack_pose.pyï¼‰"""
        if keypoints is None or len(keypoints) < 17:
            return
            
        pose_feat = extract_pose_features(keypoints)
        if pose_feat is not None:
            self.pose_features.append(pose_feat)
            if self.initial_pose_feature is None:
                self.initial_pose_feature = pose_feat
            if self.stability > 0.8 and len(self.stable_pose_features) < 3:
                self.stable_pose_features.append(pose_feat)
            
            # è®¡ç®—å§¿æ€å¯è§åº¦å’Œç½®ä¿¡åº¦
            valid_kpts = keypoints[(keypoints[:, 0] > 0) & (keypoints[:, 1] > 0)]
            visibility = len(valid_kpts) / 17.0 if len(keypoints) >= 17 else 0.0
            score = visibility  # ç®€å•çš„ç½®ä¿¡åº¦ä¼°è®¡
            
            # æ›´æ–°å§¿æ€ä¿¡æ¯
            self.update_pose(keypoints, visibility, score)

    def compare_pose(self, keypoints):
        """æ¯”è¾ƒå§¿æ€ç›¸ä¼¼åº¦ï¼ˆæ¥è‡ªtrack_pose.pyï¼‰"""
        if not any([self.initial_pose_feature is not None, self.stable_pose_features]):
             return 0.0
        
        candidate_feature = extract_pose_features(keypoints)
        if candidate_feature is None:
            return 0.0

        max_similarity = 0.0
        
        # ä¸åˆå§‹å§¿æ€æ¯”è¾ƒ
        if self.initial_pose_feature is not None:
            max_similarity = max(max_similarity, pose_similarity(self.initial_pose_feature, candidate_feature))
            
        # ä¸ç¨³å®šå§¿æ€æ¯”è¾ƒ
        for feature in self.stable_pose_features:
            max_similarity = max(max_similarity, pose_similarity(feature, candidate_feature))
            
        return max_similarity

    def update(self, x, y, w, h, conf, depth_map=None):
        current_time = time.time()
        dt = max(0.01, current_time - self.last_update_time)
        self.last_update_time = current_time

        self.consecutive_frames += 1
        self.stability = min(1.0, self.consecutive_frames / 30.0)
        self.lock_strength = min(1.0, self.lock_strength + 0.1 * (0.5 + self.stability * 0.5))

        if self.position:
            prev_x, prev_y = self.position
            vx = (x - prev_x) / dt
            vy = (y - prev_y) / dt
            smooth_factor = 0.7
            self.velocity = (
                smooth_factor * vx + (1 - smooth_factor) * self.velocity[0],
                smooth_factor * vy + (1 - smooth_factor) * self.velocity[1]
            )

        self.position = (x, y)
        self.size = (w, h)
        self.confidence = conf
        self.timestamp = current_time
        self.last_seen = current_time
        self.lost_frame_count = 0
        self.trajectory.append((x, y, self.timestamp))

        if not np.isnan(x) and not np.isnan(y):
            measurement = np.array([[x], [y]], dtype=np.float32)
            self.kalman.correct(measurement)

        if depth_map is not None:
            self.world_position = calculate_3d_coordinates(depth_map, (x, y), (w, h))
            if self.world_position != (0, 0, 0) and not any(math.isnan(val) for val in self.world_position):
                X, Y, Z = self.world_position
                if Z > 0.001:
                    self.distance = math.sqrt(X**2 + Y**2 + Z**2)
                    self.yaw = math.atan2(X, Z)
                    distance_xy = math.sqrt(X**2 + Z**2)
                    self.pitch = math.atan2(Y, distance_xy) if distance_xy > 0 else 0

    def predict_next_position(self):
        prediction = self.kalman.predict()
        return prediction[0][0], prediction[1][0]

    def mark_lost(self):
        self.lost_frame_count += 1
        self.lock_strength = max(0.3, self.lock_strength - 0.05)
        self.consecutive_frames = 0
        self.stability = 0.0
        self.pose_landmarks = None  # æ¸…é™¤å§¿æ€ä¿¡æ¯

        if self.lost_frame_count > 50:
            self.active = False

    def get_state(self):
        return {
            'id': self.target_id,
            'distance': self.distance,
            'yaw': self.yaw,
            'pitch': self.pitch,
            'position': self.position,
            'active': self.active,
            'lock_strength': self.lock_strength,
            'pose_score': self.pose_score
        }

    def output_state(self):
        current_time = time.time()
        if current_time - self.last_output_time > 0.2 and self.active:
            status = "æ´»åŠ¨" if self.active else f"ä¸¢å¤±({self.lost_frame_count}å¸§)"
            if self.world_position and not any(math.isnan(val) for val in self.world_position):
                X, Y, Z = self.world_position
                print(f"ç›®æ ‡ID {self.target_id} [{status}]: "
                      f"ä½ç½®=({X:.2f}m, {Y:.2f}m, {Z:.2f}m), "
                      f"è·ç¦»={self.distance:.2f}m, "
                      f"æ–¹ä½è§’={math.degrees(self.yaw):.2f}Â°, "
                      f"ä¿¯ä»°è§’={math.degrees(self.pitch):.2f}Â°, "
                      f"å§¿æ€ç½®ä¿¡åº¦={self.pose_score:.2f}, "
                      f"é”å®šå¼ºåº¦={self.lock_strength:.2f}")
            else:
                print(f"ç›®æ ‡ID {self.target_id} [{status}]: "
                      f"ä½ç½®=({self.position[0]:.1f}, {self.position[1]:.1f}), "
                      f"å§¿æ€ç½®ä¿¡åº¦={self.pose_score:.2f}, "
                      f"é”å®šå¼ºåº¦={self.lock_strength:.2f}")
            self.last_output_time = current_time


# ä¸‰ç»´åæ ‡è®¡ç®—å‡½æ•°
def calculate_3d_coordinates(depth_map, center_point, size=None):
    u, v = int(center_point[0]), int(center_point[1])
    height, width = depth_map.shape

    if size is None:
        w, h = 1, 1
    else:
        w, h = size

    roi_size = max(10, min(50, w // 2, h // 2))
    x1 = max(0, u - roi_size)
    y1 = max(0, v - roi_size)
    x2 = min(width - 1, u + roi_size)
    y2 = min(height - 1, v + roi_size)
    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

    if x1 >= x2 or y1 >= y2:
        return (0, 0, 0)

    depth_roi = depth_map[y1:y2, x1:x2]
    valid_mask = (depth_roi > 300) & (depth_roi < 8000)

    if not np.any(valid_mask):
        return (0, 0, 0)

    valid_depths = depth_roi[valid_mask]
    median_depth = np.median(valid_depths)
    weights = 1.0 / (np.abs(valid_depths - median_depth) + 1e-5)
    weights /= np.sum(weights)
    weighted_depth = np.sum(valid_depths * weights)

    Z_cam = weighted_depth / 1000.0

    if Z_cam <= 0.3 or Z_cam > 15.0:
        return (0, 0, 0)

    fx = 860.0
    fy = 860.0
    cx = width / 2
    cy = height / 2

    try:
        # ç›¸æœºåæ ‡ç³»åæ ‡
        X_cam = (u - cx) * Z_cam / fx
        Y_cam = (v - cy) * Z_cam / fy
        
        # è½¬æ¢ä¸ºä¸–ç•Œåæ ‡ç³»
        # ç›¸æœºåæ ‡ç³»ï¼šXè½´å‘å³ï¼ŒYè½´å‘ä¸‹ï¼ŒZè½´å‘å‰
        # ä¸–ç•Œåæ ‡ç³»ï¼šXè½´å‘å‰ï¼ŒYè½´å‘å·¦ï¼ŒZè½´å‘ä¸Š
        X_world = Z_cam      # Xè½´å‘å‰ï¼ˆåŸç›¸æœºåæ ‡ç³»çš„Zè½´ï¼‰
        Y_world = -X_cam     # Yè½´å‘å·¦ï¼ˆåŸç›¸æœºåæ ‡ç³»çš„Xè½´å–åï¼‰
        Z_world = -Y_cam     # Zè½´å‘ä¸Šï¼ˆåŸç›¸æœºåæ ‡ç³»çš„Yè½´å–åï¼‰
        
    except ZeroDivisionError:
        return (0, 0, 0)

    if any(math.isnan(val) for val in (X_world, Y_world, Z_world)):
        return (0, 0, 0)

    return (X_world, Y_world, Z_world)


# å•ç›®æ ‡è·Ÿè¸ªç®¡ç†å™¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
class MultiTargetManager:
    def __init__(self):
        self.targets = {}
        self.next_id = 0
        self.active_target_id = None
        self.target_class = "person"
        self.last_detection_time = time.time()
        self.follow_target_id = None  # å®¢æˆ·ç«¯æŒ‡å®šçš„è·Ÿéšç›®æ ‡ID
        self.follow_only_mode = False  # æ˜¯å¦åªè·Ÿè¸ªæŒ‡å®šç›®æ ‡
        self.reappear_threshold = 0.6  # é‡æ–°å‡ºç°åŒ¹é…é˜ˆå€¼
        self.initial_feature_start = None  # åˆå§‹ç‰¹å¾æ”¶é›†å¼€å§‹æ—¶é—´
        self.initial_feature_duration = 10  # å‡å°‘ç‰¹å¾æ”¶é›†æ—¶é—´

    def get_new_target_id(self):
        self.next_id += 1
        return self.next_id

    def set_follow_target(self, target_id):
        """è®¾ç½®å®¢æˆ·ç«¯æŒ‡å®šçš„è·Ÿéšç›®æ ‡ï¼Œå¯ç”¨å•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼"""
        if target_id is None or target_id == 0:
            self.follow_target_id = None
            self.follow_only_mode = False
            print(f"ğŸ›‘ åœæ­¢è·Ÿéšç›®æ ‡ï¼Œæ¢å¤å¤šç›®æ ‡æ£€æµ‹")
        else:
            self.follow_target_id = target_id
            self.follow_only_mode = True  # å¯ç”¨å•ç›®æ ‡æ¨¡å¼
            if target_id in self.targets:
                self.set_active_target(target_id)
                print(f"ğŸ¯ å•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼ï¼šåªè·Ÿéšç›®æ ‡ ID: {target_id}")
                # æ¸…ç†å…¶ä»–ç›®æ ‡ä»¥èŠ‚çœèµ„æº
                self.cleanup_non_follow_targets()
                # å¼€å§‹ç‰¹å¾æ”¶é›†
                if self.initial_feature_start is None:
                    self.initial_feature_start = time.time()
            else:
                print(f"âš ï¸ ç›®æ ‡ ID {target_id} å½“å‰ä¸å­˜åœ¨ï¼Œå°†åœ¨æ£€æµ‹åˆ°æ—¶å¼€å§‹è·Ÿéš")

    def cleanup_non_follow_targets(self):
        """æ¸…ç†éè·Ÿéšç›®æ ‡ä»¥èŠ‚çœèµ„æº"""
        if self.follow_target_id is None:
            return
        
        targets_to_remove = []
        for target_id, target in self.targets.items():
            if target_id != self.follow_target_id:
                targets_to_remove.append(target_id)
        
        for target_id in targets_to_remove:
            del self.targets[target_id]
            print(f"ğŸ—‘ï¸ æ¸…ç†éè·Ÿéšç›®æ ‡ ID: {target_id}")
        
        print(f"ğŸ’¡ å•ç›®æ ‡æ¨¡å¼ï¼šä¿ç•™ç›®æ ‡ ID {self.follow_target_id}ï¼Œæ¸…ç†äº† {len(targets_to_remove)} ä¸ªå…¶ä»–ç›®æ ‡")

    def create_target(self, frame, box, cls_id, conf, depth_map):
        """æç®€å•ç›®æ ‡æ¨¡å¼ï¼šåªå…è®¸åˆ›å»ºä¸€ä¸ªç›®æ ‡ï¼Œä¸”åªä¿ç•™è¯¥ç›®æ ‡ç‰¹å¾"""
        if self.follow_only_mode:
            if self.follow_target_id and self.follow_target_id in self.targets:
                return None
        # æ¸…ç©ºæ‰€æœ‰æ—§ç›®æ ‡å’Œç‰¹å¾ï¼ˆæç®€ï¼‰
        self.targets.clear()
        feature_storage.clear_all_features()
        target_id = self.get_new_target_id()
        x1, y1, x2, y2 = box
        center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
        bbox_width, bbox_height = abs(x2 - x1), abs(y2 - y1)
        new_target = TargetState(target_id)
        new_target.update(center_x, center_y, bbox_width, bbox_height, conf, depth_map)
        new_target.update_reid_features(frame, (x1, y1, x2, y2), is_full_body=True)
        self.targets[target_id] = new_target
        self.set_active_target(target_id)
        self.follow_target_id = target_id
        self.follow_only_mode = True
        self.initial_feature_start = time.time()
        print(f"ğŸ¯ æç®€å•ç›®æ ‡æ¨¡å¼ï¼šåˆ›å»ºå¹¶è·Ÿéšç›®æ ‡ ID: {target_id}")
        return new_target

    def update_target(self, target, x, y, w, h, conf, depth_map):
        target.update(x, y, w, h, conf, depth_map)

    def find_best_match(self, frame, boxes, cls_ids, confs, depth_map, keypoints_data=None):
        """ä¼˜åŒ–çš„åŒ¹é…ç®—æ³•ï¼šå•ç›®æ ‡æ¨¡å¼ä¸‹åªåŒ¹é…è·Ÿéšç›®æ ‡ï¼Œé›†æˆå§¿æ€åŒ¹é…é€»è¾‘"""
        matches = []
        unmatched_detections = list(range(len(boxes)))
        
        # å¦‚æœå¤„äºå•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼ï¼ŒåªåŒ¹é…è·Ÿéšç›®æ ‡
        if self.follow_only_mode and self.follow_target_id:
            target = self.targets.get(self.follow_target_id)
            if target and target.active:
                best_match_score = 0.0
                best_detection_idx = -1
                
                for i in range(len(boxes)):
                    cls_id = cls_ids[i]
                    if model.names[cls_id] != self.target_class:
                        continue

                    x1, y1, x2, y2 = boxes[i]
                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2

                    # é›†æˆå§¿æ€åŒ¹é…é€»è¾‘ï¼ˆæ¥è‡ªtrack_pose.pyï¼‰
                    match_score = 0.0
                    
                    # ReIDç‰¹å¾ç›¸ä¼¼åº¦ (æƒé‡0.7)
                    reid_sim = target.compare_signature(frame, (x1, y1, x2, y2))
                    match_score += 0.6 * reid_sim
                    
                    # å§¿æ€ç›¸ä¼¼åº¦ (æƒé‡0.2)
                    pose_sim = 0.0
                    if keypoints_data is not None and i < len(keypoints_data):
                        keypoints = keypoints_data[i]
                        pose_sim = target.compare_pose(keypoints)
                    match_score += 0.3 * pose_sim

                    # ä½ç½®è·ç¦» (æƒé‡0.1)
                    if target.position:
                        px, py = target.position
                        distance = math.sqrt((center_x - px)**2 + (center_y - py)**2)
                        position_score = max(0, 1 - distance / 300)  # å¢åŠ æœç´¢èŒƒå›´
                        match_score += 0.1 * position_score

                    if match_score > best_match_score and match_score > 0.65:  # ç¨å¾®é™ä½åŒ¹é…é˜ˆå€¼
                        best_match_score = match_score
                        best_detection_idx = i
                
                if best_detection_idx >= 0:
                    matches.append((self.follow_target_id, best_detection_idx, best_match_score))
                    if best_detection_idx in unmatched_detections:
                        unmatched_detections.remove(best_detection_idx)
                
                # å•ç›®æ ‡æ¨¡å¼ä¸‹ï¼Œç§»é™¤æ‰€æœ‰å…¶ä»–æœªåŒ¹é…çš„æ£€æµ‹ä»¥é¿å…åˆ›å»ºæ–°ç›®æ ‡
                if self.follow_only_mode:
                    unmatched_detections = []
        else:
            # å¤šç›®æ ‡æ¨¡å¼çš„åŸå§‹é€»è¾‘ï¼ˆä¿ç•™ç”¨äºéå•ç›®æ ‡åœºæ™¯ï¼‰
            for target_id, target in self.targets.items():
                if not target.active:
                    continue
                    
                best_match_score = 0.0
                best_detection_idx = -1
                
                for i in range(len(boxes)):
                    cls_id = cls_ids[i]
                    if model.names[cls_id] != self.target_class:
                        continue

                    x1, y1, x2, y2 = boxes[i]
                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2

                    match_score = 0.0
                    # ReIDç‰¹å¾ç›¸ä¼¼åº¦ (æƒé‡0.6)
                    reid_sim = target.compare_signature(frame, (x1, y1, x2, y2))
                    match_score += 0.6 * reid_sim
                    
                    # å§¿æ€ç›¸ä¼¼åº¦ (æƒé‡0.2)
                    pose_sim = 0.0
                    if keypoints_data is not None and i < len(keypoints_data):
                        keypoints = keypoints_data[i]
                        pose_sim = target.compare_pose(keypoints)
                    match_score += 0.2 * pose_sim

                    # ä½ç½®ç›¸ä¼¼åº¦ (æƒé‡0.2)
                    if target.position:
                        px, py = target.position
                        distance = math.sqrt((center_x - px)**2 + (center_y - py)**2)
                        position_score = max(0, 1 - distance / 200)
                        match_score += 0.2 * position_score

                    if match_score > best_match_score and match_score > 0.5:
                        best_match_score = match_score
                        best_detection_idx = i
                
                if best_detection_idx >= 0:
                    matches.append((target_id, best_detection_idx, best_match_score))
        
        # è§£å†³å†²çª
        final_matches = {}
        used_detections = set()
        matches.sort(key=lambda x: x[2], reverse=True)
        
        for target_id, detection_idx, score in matches:
            if detection_idx not in used_detections:
                final_matches[target_id] = detection_idx
                used_detections.add(detection_idx)
                if detection_idx in unmatched_detections:
                    unmatched_detections.remove(detection_idx)
        
        return final_matches, unmatched_detections

    def update_inactive_targets(self):
        """æç®€å•ç›®æ ‡æ¨¡å¼ï¼šä¸¢å¤±åå½»åº•æ¸…ç†ç›®æ ‡å’Œç‰¹å¾"""
        current_time = time.time()
        if self.follow_only_mode and self.follow_target_id:
            target = self.targets.get(self.follow_target_id)
            if target:
                if not target.active:
                    target.mark_lost()
                    # ä¸¢å¤±è¶…è¿‡ä¸€å®šæ—¶é—´æˆ–é”å®šå¼ºåº¦è¿‡ä½ï¼Œå½»åº•æ¸…ç†
                    if target.lock_strength < 0.3:
                        print(f"ğŸ—‘ï¸ ä¸¢å¤±ç›®æ ‡ï¼Œå½»åº•æ¸…ç† ID: {self.follow_target_id}")
                        del self.targets[self.follow_target_id]
                        self.follow_target_id = None
                        self.follow_only_mode = False
                        feature_storage.clear_all_features()
                elif target.active and target.lost_frame_count > 0:
                    pred_x, pred_y = target.predict_next_position()
                    target.position = (pred_x, pred_y)
                    target.last_seen = current_time
        else:
            # å¤šç›®æ ‡æ¨¡å¼ï¼šæ›´æ–°æ‰€æœ‰ç›®æ ‡
            for target_id, target in list(self.targets.items()):
                if not target.active:
                    target.mark_lost()
                    if target.lock_strength < 0.3 or current_time - target.last_seen > 10.0:
                        print(f"ç§»é™¤éæ´»åŠ¨ç›®æ ‡ ID: {target_id}")
                        del self.targets[target_id]
                elif target.active and target.lost_frame_count > 0:
                    pred_x, pred_y = target.predict_next_position()
                    target.position = (pred_x, pred_y)
                    target.last_seen = current_time

    def set_active_target(self, target_id):
        if target_id in self.targets:
            self.active_target_id = target_id
            print(f"è®¾ç½®æ´»åŠ¨ç›®æ ‡ ID: {target_id}")

    def get_active_target(self):
        return self.targets.get(self.active_target_id)

    def get_follow_target(self):
        """è·å–å½“å‰è·Ÿéšçš„ç›®æ ‡"""
        if self.follow_target_id and self.follow_target_id in self.targets:
            return self.targets[self.follow_target_id]
        return None
    
    def get_all_targets(self):
        """è·å–æ‰€æœ‰ç›®æ ‡çš„åˆ—è¡¨"""
        return list(self.targets.values())
        
    def process_detections(self, frame, boxes, cls_ids, confs, depth_map, keypoints_data=None):
        """ä¼˜åŒ–çš„æ£€æµ‹å¤„ç†ï¼šå•ç›®æ ‡æ¨¡å¼ä¸‹ä»…å¤„ç†è·Ÿéšç›®æ ‡ï¼Œé›†æˆå§¿æ€åŒ¹é…"""
        final_matches, unmatched_detections = self.find_best_match(frame, boxes, cls_ids, confs, depth_map, keypoints_data)
        
        # æ›´æ–°åŒ¹é…çš„ç›®æ ‡
        for target_id, detection_idx in final_matches.items():
            target = self.targets[target_id]
            x1, y1, x2, y2 = boxes[detection_idx]
            cls_id = cls_ids[detection_idx]
            conf = confs[detection_idx]
            
            center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
            bbox_width, bbox_height = abs(x2 - x1), abs(y2 - y1)
            
            self.update_target(target, center_x, center_y, bbox_width, bbox_height, conf, depth_map)
            
            # æ›´æ–°å§¿æ€ç‰¹å¾ï¼ˆåŸºäºYOLOå…³é”®ç‚¹ï¼Œæ¥è‡ªtrack_pose.pyçš„é€»è¾‘ï¼‰
            if keypoints_data is not None and detection_idx < len(keypoints_data):
                keypoints = keypoints_data[detection_idx]
                target.update_pose_features(keypoints)
            
            # å¦‚æœæ˜¯è·Ÿéšç›®æ ‡ï¼Œè¿›è¡Œç‰¹å¾æ”¶é›†
            if target_id == self.follow_target_id:
                # [ä¿®æ”¹] æŒç»­æ›´æ–°ç‰¹å¾ï¼Œè€Œä¸ä»…ä»…æ˜¯åœ¨å‰10ç§’
                if target.stability > 0.7: # åªåœ¨ç›®æ ‡ç¨³å®šæ—¶æ›´æ–°
                    current_time = time.time()
                    if current_time - target.last_feature_save_time >= 1.0:  # é™ä½ç‰¹å¾ä¿å­˜é¢‘ç‡
                        print(f"ğŸ”„ ä¸ºç›®æ ‡ {target_id} æŒç»­æ›´æ–°ReIDç‰¹å¾ (ç¨³å®šæ€§: {target.stability:.2f})")
                        target.update_reid_features(frame, (x1, y1, x2, y2), is_full_body=False)
                        target.last_feature_save_time = current_time
        
        # åˆ›å»ºæ–°ç›®æ ‡ï¼ˆå•ç›®æ ‡æ¨¡å¼ä¸‹é™åˆ¶åˆ›å»ºï¼‰
        for detection_idx in unmatched_detections:
            cls_id = cls_ids[detection_idx]
            if model.names[cls_id] == self.target_class and confs[detection_idx] > 0.6:
                # å•ç›®æ ‡æ¨¡å¼ä¸‹ï¼Œåªæœ‰åœ¨æ²¡æœ‰è·Ÿéšç›®æ ‡æˆ–æŒ‡å®šIDæ—¶æ‰åˆ›å»º
                if not self.follow_only_mode or (self.follow_target_id and len(self.targets) == 0):
                    x1, y1, x2, y2 = boxes[detection_idx]
                    center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2
                    
                    # è¿‡æ»¤è¾¹ç¼˜æ£€æµ‹
                    if center_x < 50 or center_x > frame.shape[1] - 50 or center_y < 50 or center_y > frame.shape[0] - 50:
                        continue
                    
                    new_target = self.create_target(frame, [x1, y1, x2, y2], cls_id, confs[detection_idx], depth_map)
                    if new_target:
                        # ä¸ºæ–°ç›®æ ‡åˆå§‹åŒ–å§¿æ€ç‰¹å¾ï¼ˆåŸºäºYOLOå…³é”®ç‚¹ï¼‰
                        if keypoints_data is not None and detection_idx < len(keypoints_data):
                            keypoints = keypoints_data[detection_idx]
                            new_target.update_pose_features(keypoints)
        
        return final_matches, unmatched_detections

    def output_all_states(self):
        """ä¼˜åŒ–ï¼šåªè¾“å‡ºè·Ÿéšç›®æ ‡çš„çŠ¶æ€"""
        if self.follow_only_mode and self.follow_target_id:
            target = self.targets.get(self.follow_target_id)
            if target:
                target.output_state()
        else:
            # å¤šç›®æ ‡æ¨¡å¼æ‰è¾“å‡ºæ‰€æœ‰çŠ¶æ€
            for target in self.targets.values():
                target.output_state()

    def has_active_targets(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒç›®æ ‡"""
        if self.follow_only_mode and self.follow_target_id:
            target = self.targets.get(self.follow_target_id)
            return target and target.active
        else:
            return any(target.active for target in self.targets.values())

    def draw_target_list(self, vis_frame, all_detected_targets):
        """åœ¨å±å¹•ä¸Šç»˜åˆ¶æ‰€æœ‰ç›®æ ‡IDåˆ—è¡¨"""
        if not all_detected_targets:
            return
        
        # åœ¨å³ä¾§ç»˜åˆ¶ç›®æ ‡åˆ—è¡¨
        list_x = vis_frame.shape[1] - 250
        list_y = 100
        
        # ç»˜åˆ¶èƒŒæ™¯
        cv2.rectangle(vis_frame, (list_x - 10, list_y - 30), 
                     (vis_frame.shape[1] - 10, list_y + len(all_detected_targets) * 25 + 50), 
                     (0, 0, 0), -1)
        cv2.rectangle(vis_frame, (list_x - 10, list_y - 30), 
                     (vis_frame.shape[1] - 10, list_y + len(all_detected_targets) * 25 + 50), 
                     (255, 255, 255), 2)
        
        # æ ‡é¢˜
        cv2.putText(vis_frame, "DETECTED TARGETS", (list_x, list_y - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºè·Ÿéšç›®æ ‡ä¿¡æ¯
        follow_target = self.get_follow_target()
        if follow_target:
            follow_text = f"FOLLOW: ID-{follow_target.target_id}"
            cv2.putText(vis_frame, follow_text, (list_x, list_y + 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        else:
            cv2.putText(vis_frame, "FOLLOW: NONE", (list_x, list_y + 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)
        
        # ç»˜åˆ¶ç›®æ ‡åˆ—è¡¨
        current_y = list_y + 40
        for i, target_info in enumerate(all_detected_targets):
            target_id = target_info['id']
            conf = target_info['conf']
            status = target_info['status']
            is_follow = target_info['is_follow_target']
            
            # è®¾ç½®é¢œè‰²
            if is_follow:
                color = (0, 0, 255)  # çº¢è‰² - è·Ÿéšç›®æ ‡
                prefix = "â–º "
            elif status == 'NEW':
                color = (0, 255, 0)  # ç»¿è‰² - æ–°æ£€æµ‹
                prefix = "â— "
            else:
                color = (255, 255, 0)  # é’è‰² - å·²è·Ÿè¸ªç›®æ ‡
                prefix = "â—‹ "
            
            # ç»˜åˆ¶ç›®æ ‡ä¿¡æ¯
            if target_id == 'NEW':
                text = f"{prefix}NEW ({conf:.2f})"
            else:
                text = f"{prefix}ID-{target_id} ({conf:.2f})"
            
            cv2.putText(vis_frame, text, (list_x, current_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            current_y += 25
        
        # æ˜¾ç¤ºè¯´æ˜
        instructions_y = current_y + 10
        cv2.putText(vis_frame, "â–º = Following", (list_x, instructions_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
        cv2.putText(vis_frame, "â—‹ = Tracked", (list_x, instructions_y + 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        cv2.putText(vis_frame, "â— = New", (list_x, instructions_y + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)

# å…¨å±€æ¨¡å‹å˜é‡
model = None

# å¸§æ•è·çº¿ç¨‹
class FrameCaptureThread(threading.Thread):
    def __init__(self, device, frame_queue):
        super().__init__()
        self.device = device
        self.frame_queue = frame_queue
        self.running = True
        self.q_rgb = None
        self.q_depth = None

    def initialize_queues(self):
        """åˆå§‹åŒ–è®¾å¤‡é˜Ÿåˆ—"""
        try:
            self.q_rgb = self.device.getOutputQueue(name="rgb", maxSize=4, blocking=True)
            self.q_depth = self.device.getOutputQueue(name="depth", maxSize=4, blocking=True)
            return True
        except Exception as e:
            print(f"é˜Ÿåˆ—åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def run(self):
        if not self.initialize_queues():
            print("å¸§æ•è·çº¿ç¨‹å¯åŠ¨å¤±è´¥ï¼šæ— æ³•åˆå§‹åŒ–é˜Ÿåˆ—")
            return

        while self.running:
            try:
                in_rgb = self.q_rgb.get()
                in_depth = self.q_depth.get()
                if in_rgb is not None and in_depth is not None:
                    frame = in_rgb.getCvFrame()
                    depth_frame = in_depth.getFrame()
                    
                    if self.frame_queue.full():
                        self.frame_queue.get_nowait() # ä¸¢å¼ƒæ—§å¸§
                    self.frame_queue.put((frame, depth_frame))
            except Exception as e:
                print(f"ç›¸æœºçº¿ç¨‹é”™è¯¯: {e}")
                self.running = False
        print("ç›¸æœºçº¿ç¨‹å·²åœæ­¢ã€‚")

    def stop(self):
        self.running = False

# å¤„ç†çº¿ç¨‹ï¼ˆæ”¯æŒå¯è§†åŒ–å¼€å…³ï¼‰
class ProcessingThread(threading.Thread):
    def __init__(self, frame_queue, result_queue, stop_event, grpc_server_address='localhost:50051', enable_visualization=True):
        super().__init__()
        self.frame_queue = frame_queue
        self.result_queue = result_queue
        self.stop_event = stop_event
        self.target_manager = MultiTargetManager()
        self.special_target_missing_start = None
        self.fps = 0
        self.frame_count = 0
        self.start_time = time.time()
        
        # å¯è§†åŒ–å¼€å…³
        self.enable_visualization = enable_visualization
        
        # åˆå§‹åŒ–gRPCå®¢æˆ·ç«¯
        self.grpc_client = TrackingGRPCClient(grpc_server_address)
        self.grpc_enabled = False
        self.tracking_start_time = None
        
        # ç¬¬ä¸€æ¬¡è·Ÿè¸ªæŒ‡ä»¤æ ‡å¿—
        self.first_tracking_command = True

    def run(self):
        global model
        
        # å°è¯•è¿æ¥gRPCæœåŠ¡å™¨
        print("å°è¯•è¿æ¥gRPCæœåŠ¡å™¨...")
        if self.grpc_client.connect():
            self.grpc_enabled = True
            print("gRPCé€šä¿¡å·²å¯ç”¨")
        else:
            self.grpc_enabled = False
            print("gRPCé€šä¿¡æœªå¯ç”¨ï¼Œç»§ç»­è¿è¡Œæœ¬åœ°æ¨¡å¼")
        
        try:
            model = YOLO('yolo11n-pose.pt')
            print("YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.stop_event.set()
            return

        while not self.stop_event.is_set():
            try:
                frame, depth_frame = self.frame_queue.get(timeout=1)
            except queue.Empty:
                continue

            if depth_frame.shape != (480, 640):
                depth_frame = cv2.resize(depth_frame, (640, 480), interpolation=cv2.INTER_NEAREST)
            depth_frame = cv2.medianBlur(depth_frame.astype(np.float32), 5).astype(np.uint16)

            # --- FPS è®¡ç®— ---
            self.frame_count += 1
            current_time = time.time()
            if self.frame_count % 30 == 0:  # å‡å°‘FPSæ‰“å°é¢‘ç‡
                elapsed = current_time - self.start_time
                self.fps = 30 / elapsed if elapsed > 0 else 0
                self.start_time = current_time
                self.frame_count = 0
                print(f"FPS: {self.fps:.1f}")

            # --- ç›®æ ‡æ£€æµ‹ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰---
            try:
                # ä¼˜åŒ–æ£€æµ‹å‚æ•°ä»¥æé«˜é€Ÿåº¦
                results = model.track(
                    frame,
                    imgsz=640,  # å‡å°è¾“å…¥å°ºå¯¸æé«˜é€Ÿåº¦
                    tracker='botsort.yaml',
                    conf=0.6,  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼å‡å°‘è¯¯æ£€
                    iou=0.6,   # æé«˜IOUé˜ˆå€¼å‡å°‘é‡å æ¡†
                    persist=True,
                    half=True,
                    verbose=False,
                    max_det=10,  # é™åˆ¶æœ€å¤§æ£€æµ‹æ•°é‡
                    agnostic_nms=True  # å¯ç”¨ç±»åˆ«æ— å…³çš„NMS
                )
            except Exception as e:
                print(f"ç›®æ ‡æ£€æµ‹å¤±è´¥: {e}")
                results = []

            # --- æ£€æŸ¥gRPCè·ŸéšæŒ‡ä»¤ ---
            if self.grpc_enabled:
                try:
                    follow_commands = self.grpc_client.get_follow_commands()
                    if follow_commands:
                        for cmd in follow_commands:
                            if cmd['action'] == 'follow' and 'target_id' in cmd:
                                target_id = cmd['target_id']
                                
                                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ”¶åˆ°è·Ÿè¸ªæŒ‡ä»¤ï¼Œé‡ç½®æ‰€æœ‰ç‰¹å¾å¹¶å¯ç”¨å•ç›®æ ‡æ¨¡å¼
                                if self.first_tracking_command:
                                    print("ğŸ”„ é¦–æ¬¡è·Ÿè¸ªæŒ‡ä»¤ï¼Œé‡ç½®ç‰¹å¾åº“å¹¶å¯ç”¨å•ç›®æ ‡æ¨¡å¼...")
                                    feature_storage.clear_all_features()
                                    self.target_manager.targets.clear()
                                    self.target_manager.next_id = 0
                                    self.target_manager.active_target_id = None
                                    self.target_manager.set_follow_target(target_id)
                                    self.tracking_start_time = time.time()
                                    self.first_tracking_command = False
                                    print(f"âœ… å¯ç”¨å•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼ï¼Œç›®æ ‡ID: {target_id}")
                                else:
                                    self.target_manager.set_follow_target(target_id)
                                
                            elif cmd['action'] == 'stop_follow':
                                self.first_tracking_command = True
                                self.target_manager.set_follow_target(None)
                                self.tracking_start_time = None
                                print("ğŸ›‘ åœæ­¢è·Ÿè¸ªï¼Œé€€å‡ºå•ç›®æ ‡æ¨¡å¼")
                except Exception as e:
                    pass  # é™é»˜å¤„ç†gRPCé”™è¯¯

            # --- ç»“æœå¤„ç†å’Œè·Ÿè¸ªï¼ˆå¤š/å•ç›®æ ‡å¯è§†åŒ–ï¼‰---
            vis_frame = frame.copy() if self.enable_visualization else None
            all_detected_targets = []
            if results and results[0].boxes is not None and len(results[0].boxes) > 0:
                boxes = results[0].boxes
                cls_ids = boxes.cls.cpu().numpy().astype(int)
                confs = boxes.conf.cpu().numpy()
                boxes_xyxy = boxes.xyxy.cpu().numpy()
                
                # æå–å…³é”®ç‚¹æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                keypoints_data = None
                if hasattr(results[0], 'keypoints') and results[0].keypoints is not None:
                    keypoints_tensor = results[0].keypoints.xy.cpu().numpy()  # shape: (n_detections, 17, 2)
                    keypoints_data = []
                    for i in range(len(keypoints_tensor)):
                        # è½¬æ¢ä¸º (17, 2) æ ¼å¼ï¼Œæ¯ä¸ªå…³é”®ç‚¹ [x, y]
                        kpts = keypoints_tensor[i]  # (17, 2)
                        keypoints_data.append(kpts)

                final_matches, unmatched_detections = self.target_manager.process_detections(
                    frame, boxes_xyxy, cls_ids, confs, depth_frame, keypoints_data
                )

                # å‘é€è·Ÿéšç›®æ ‡æ•°æ®åˆ°gRPCï¼ˆåªæœ‰åœ¨å•ç›®æ ‡æ¨¡å¼ä¸‹ä¸”è·Ÿéšç›®æ ‡è¢«æˆåŠŸåŒ¹é…æ—¶æ‰å‘é€ï¼‰
                follow_target = self.target_manager.get_follow_target()
                if (follow_target and follow_target.active and self.grpc_enabled and 
                    self.target_manager.follow_only_mode and 
                    follow_target.target_id in final_matches):
                    try:
                        self.grpc_client.send_target_coordinates(follow_target)
                        self.grpc_client.send_tracking_status(
                            is_active=True,
                            target_id=follow_target.target_id,
                            tracking_time=time.time() - self.tracking_start_time if self.tracking_start_time else 0.0
                        )
                    except Exception:
                        pass
                elif self.grpc_enabled and self.target_manager.follow_only_mode:
                    # å•ç›®æ ‡æ¨¡å¼ä¸‹ï¼Œå¦‚æœè·Ÿéšç›®æ ‡æœªè¢«åŒ¹é…åˆ°ï¼Œå‘é€åœæ­¢åæ ‡
                    try:
                        dummy_state = type('DummyState', (), {'active': False, 'target_id': 0, 'world_position': None, 'distance': 0, 'yaw': 0, 'pitch': 0, 'confidence': 0})()
                        self.grpc_client.send_target_coordinates(dummy_state)
                        self.grpc_client.send_tracking_status(is_active=False, target_id=0, tracking_time=0.0)
                    except Exception:
                        pass

                # --------- å¯è§†åŒ– ---------
                if self.enable_visualization and vis_frame is not None:
                    # å•ç›®æ ‡æ¨¡å¼ï¼šåªç”»è·Ÿéšç›®æ ‡
                    if self.target_manager.follow_only_mode and follow_target:
                        if follow_target.target_id in final_matches:
                            detection_idx = final_matches[follow_target.target_id]
                            bbox = boxes_xyxy[detection_idx]
                            conf = confs[detection_idx]
                            self.draw_simple_box(vis_frame, bbox, follow_target.target_id, conf, (0, 0, 255), 'FOLLOW')
                    else:
                        # å¤šç›®æ ‡æ¨¡å¼ï¼šç”»æ‰€æœ‰ç›®æ ‡æ¡†å’Œå³ä¾§IDåˆ—è¡¨
                        # 1. ç”»æ‰€æœ‰å·²åŒ¹é…ç›®æ ‡
                        for target_id, detection_idx in final_matches.items():
                            target = self.target_manager.targets[target_id]
                            bbox = boxes_xyxy[detection_idx]
                            conf = confs[detection_idx]
                            is_follow = (target_id == self.target_manager.follow_target_id)
                            color = (0, 0, 255) if is_follow else (255, 255, 0)
                            status = 'FOLLOW' if is_follow else 'TRACKED'
                            self.draw_simple_box(vis_frame, bbox, target_id, conf, color, status)
                            all_detected_targets.append({
                                'id': target_id,
                                'bbox': bbox,
                                'conf': conf,
                                'is_follow_target': is_follow,
                                'status': status
                            })
                        # 2. ç”»æœªåŒ¹é…çš„æ–°ç›®æ ‡
                        for detection_idx in unmatched_detections:
                            cls_id = cls_ids[detection_idx]
                            if model.names[cls_id] == self.target_manager.target_class:
                                bbox = boxes_xyxy[detection_idx]
                                conf = confs[detection_idx]
                                self.draw_simple_box(vis_frame, bbox, 'NEW', conf, (0, 255, 0), 'NEW')
                                all_detected_targets.append({
                                    'id': 'NEW',
                                    'bbox': bbox,
                                    'conf': conf,
                                    'is_follow_target': False,
                                    'status': 'NEW'
                                })
                        # 3. å³ä¾§ç›®æ ‡IDåˆ—è¡¨
                        # self.target_manager.draw_target_list(vis_frame, all_detected_targets)
                    # ç³»ç»Ÿä¿¡æ¯
                    self.draw_info(vis_frame, depth_frame)
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œç¡®ä¿åœæ­¢å‘é€gRPCæ•°æ®ï¼ˆé€‚ç”¨äºæ‰€æœ‰æ¨¡å¼ï¼‰
                if self.grpc_enabled:
                    try:
                        dummy_state = type('DummyState', (), {'active': False, 'target_id': 0, 'world_position': None, 'distance': 0, 'yaw': 0, 'pitch': 0, 'confidence': 0})()
                        self.grpc_client.send_target_coordinates(dummy_state)
                        self.grpc_client.send_tracking_status(is_active=False, target_id=0, tracking_time=0.0)
                    except Exception:
                        pass
                # æ˜¾ç¤ºæ— ç›®æ ‡çŠ¶æ€
                if self.enable_visualization and vis_frame is not None:
                    self.draw_info(vis_frame, depth_frame)

            # æ›´æ–°ç›®æ ‡çŠ¶æ€ï¼ˆä¼˜åŒ–ï¼šä»…æ›´æ–°è·Ÿéšç›®æ ‡ï¼‰
            prev_follow_target_id = self.target_manager.follow_target_id
            self.target_manager.update_inactive_targets()
            
            # æ£€æŸ¥è·Ÿéšç›®æ ‡æ˜¯å¦è¢«æ¸…ç†ï¼Œå¦‚æœæ˜¯åˆ™å‘é€åœæ­¢åæ ‡
            if (prev_follow_target_id is not None and 
                self.target_manager.follow_target_id is None and 
                self.grpc_enabled):
                try:
                    dummy_state = type('DummyState', (), {'active': False, 'target_id': 0, 'world_position': None, 'distance': 0, 'yaw': 0, 'pitch': 0, 'confidence': 0})()
                    self.grpc_client.send_target_coordinates(dummy_state)
                    self.grpc_client.send_tracking_status(is_active=False, target_id=0, tracking_time=0.0)
                    print("ğŸ“¡ è·Ÿéšç›®æ ‡å·²ä¸¢å¤±ï¼Œå‘é€åœæ­¢åæ ‡")
                except Exception:
                    pass
            
            self.target_manager.output_all_states()
            
            # è¾“å‡ºå¯è§†åŒ–ç»“æœ
            if self.enable_visualization and vis_frame is not None and self.result_queue is not None:
                try:
                    if self.result_queue.full():
                        self.result_queue.get_nowait()  # ä¸¢å¼ƒæ—§å¸§
                    self.result_queue.put(vis_frame)
                except queue.Full:
                    pass  # é™é»˜å¤„ç†é˜Ÿåˆ—æ»¡çš„æƒ…å†µ
        
        # æ–­å¼€gRPCè¿æ¥
        if self.grpc_enabled:
            self.grpc_client.disconnect()
        
        print("å¤„ç†çº¿ç¨‹å·²åœæ­¢ã€‚")

    def reset_tracker(self):
        self.target_manager = MultiTargetManager()
        self.special_target_missing_start = None
        print("æ‰‹åŠ¨é‡ç½®ç›®æ ‡é€‰æ‹©")
    
    def draw_info(self, vis_frame, depth_frame):
        """ä¼˜åŒ–çš„ç³»ç»Ÿä¿¡æ¯ç»˜åˆ¶ï¼ˆå•ç›®æ ‡æ¨¡å¼ï¼‰"""
        # æ˜¾ç¤ºFPS
        cv2.putText(vis_frame, f"FPS: {self.fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºå•ç›®æ ‡æ¨¡å¼çŠ¶æ€
        # mode_text = "å•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼" if self.target_manager.follow_only_mode else "å¤šç›®æ ‡æ£€æµ‹æ¨¡å¼"
        # cv2.putText(vis_frame, mode_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # æ˜¾ç¤ºgRPCçŠ¶æ€
        grpc_status = "gRPC: ON" if self.grpc_enabled else "gRPC: OFF"
        grpc_color = (0, 255, 0) if self.grpc_enabled else (0, 0, 255)
        cv2.putText(vis_frame, grpc_status, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, grpc_color, 2)
        
        # æ˜¾ç¤ºè·Ÿéšç›®æ ‡ä¿¡æ¯
        follow_target = self.target_manager.get_follow_target()
        if follow_target:
            status = "ACTIVE" if follow_target.active else f"LOST({follow_target.lost_frame_count}fps)"
            cv2.putText(vis_frame, f"Follow ID:{follow_target.target_id} [{status}]", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            if follow_target.world_position and follow_target.active:
                cv2.putText(vis_frame, f"Distance: {follow_target.distance:.2f}m", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                cv2.putText(vis_frame, f"Yaw: {math.degrees(follow_target.yaw):.1f}", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                cv2.putText(vis_frame, f"Pitch: {math.degrees(follow_target.pitch):.1f}", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        else:
            cv2.putText(vis_frame, "No target selected", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)
        
        # æ˜¾ç¤ºç‰¹å¾æ”¶é›†çŠ¶æ€ï¼ˆä»…åœ¨å•ç›®æ ‡æ¨¡å¼ä¸‹ï¼‰
        if self.target_manager.follow_only_mode:
            current_time = time.time()
            if self.target_manager.initial_feature_start is not None:
                elapsed = current_time - self.target_manager.initial_feature_start
                if elapsed <= self.target_manager.initial_feature_duration:
                    remaining = self.target_manager.initial_feature_duration - elapsed
                #     cv2.putText(vis_frame, f"ç‰¹å¾æ”¶é›†ä¸­: {remaining:.1f}s", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                # elif elapsed <= self.target_manager.initial_feature_duration + 2:
                #     cv2.putText(vis_frame, "ç‰¹å¾æ”¶é›†å®Œæˆ!", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # ç®€åŒ–çš„æ§åˆ¶è¯´æ˜
        cv2.putText(vis_frame, "Q=Quit | R=Reset", (10, vis_frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    def toggle_visualization(self):
        """åˆ‡æ¢å¯è§†åŒ–å¼€å…³"""
        self.enable_visualization = not self.enable_visualization
        status = "å¯ç”¨" if self.enable_visualization else "ç¦ç”¨"
        print(f"å¯è§†åŒ–å·²{status}")
        return self.enable_visualization

    def draw_simple_box(self, vis_frame, bbox, target_id, conf, color, status):
        """ç®€åŒ–çš„ç›®æ ‡æ¡†ç»˜åˆ¶ï¼ŒåŒ…å«å§¿æ€ä¿¡æ¯ï¼ˆæé«˜æ€§èƒ½ï¼‰"""
        x1, y1, x2, y2 = map(int, bbox)
        thickness = 3 if status == 'FOLLOW' else 2
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, thickness)
        
        # è·å–ç›®æ ‡çš„å§¿æ€ä¿¡æ¯
        pose_score = 0.0
        lock_strength = 0.0
        if target_id != 'NEW' and target_id in self.target_manager.targets:
            target = self.target_manager.targets[target_id]
            pose_score = target.pose_score
            lock_strength = target.lock_strength
            
            # ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹ï¼ˆä»…åœ¨ç½®ä¿¡åº¦é«˜æ—¶ï¼‰- é€‚é…YOLOå…³é”®ç‚¹æ ¼å¼
            if target.pose_landmarks is not None and target.pose_score > 0.5:
                keypoints = target.pose_landmarks  # YOLOæ ¼å¼: (17, 2)
                if len(keypoints) >= 17:
                    for i, (kx, ky) in enumerate(keypoints):
                        if kx > 0 and ky > 0:  # æœ‰æ•ˆå…³é”®ç‚¹
                            # YOLOå…³é”®ç‚¹å·²ç»æ˜¯ç»å¯¹åæ ‡ï¼Œç›´æ¥ä½¿ç”¨
                            cx, cy = int(kx), int(ky)
                            if x1 <= cx <= x2 and y1 <= cy <= y2:
                                cv2.circle(vis_frame, (cx, cy), 2, (0, 255, 0), -1)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f"ID{target_id} {conf:.2f}"
        if status == 'FOLLOW':
            label = f"{label} [FOLLOW]"
        
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
        cv2.rectangle(vis_frame, (x1, y1 - text_height - 10), (x1 + text_width, y1), (0, 0, 0), -1)
        cv2.putText(vis_frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
        
        # ç»˜åˆ¶å§¿æ€å’Œé”å®šå¼ºåº¦ä¿¡æ¯
        if target_id != 'NEW' and status == 'FOLLOW':
            info_text = f"Pose: {pose_score:.2f} | Lock: {lock_strength:.2f}"
            cv2.putText(vis_frame, info_text, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 0), 1)
        
        # ç»˜åˆ¶ä¸­å¿ƒç‚¹
        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
        cv2.circle(vis_frame, (center_x, center_y), 5, color, -1)


# ä¸»ç¨‹åºï¼ˆé›†æˆgRPCé€šä¿¡å’Œå¯è§†åŒ–ï¼‰
def main(grpc_server='localhost:50051', enable_visualization=True):
    global reid_handler  # å£°æ˜å…¨å±€å˜é‡
    
    print(f"=== OAKå•ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ, fast-reid åº“) ===")
    print(f"gRPCæœåŠ¡å™¨åœ°å€: {grpc_server}")
    print(f"å¯è§†åŒ–çŠ¶æ€: {'å¯ç”¨' if enable_visualization else 'ç¦ç”¨'}")
    
    # --- [æ–°å¢] åˆå§‹åŒ– ReID å¤„ç†å™¨ ---
    print("æ­£åœ¨åˆå§‹åŒ–ReIDå¤„ç†å™¨...")
    reid_handler = ReIDHandler(model_path="weights/ReID_resnet50_ibn_a.pth")
    if reid_handler.model is None:
        print("é”™è¯¯: ReIDæ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡ºã€‚")
        return False
    
    # åˆ›å»ºç›¸æœºç®¡ç†å™¨
    camera_manager = CameraManager(max_retries=5, retry_delay=3)
    
    # å°è¯•è¿æ¥ç›¸æœº
    if not camera_manager.connect_camera():
        print("âŒ æ— æ³•è¿æ¥åˆ°OAKç›¸æœºï¼Œç¨‹åºé€€å‡º")
        return False
    
    device = camera_manager.get_device()
    frame_queue = queue.Queue(maxsize=1)
    result_queue = queue.Queue(maxsize=1) if enable_visualization else None
    stop_event = threading.Event()
    
    capture_thread = None
    processing_thread = None
    
    try:
        print("âœ… OAKç›¸æœºå·²è¿æ¥ï¼Œå¯åŠ¨ä¼˜åŒ–çš„å¤„ç†æµç¨‹...")
        print("ğŸ“¡ gRPCé€šä¿¡åŠŸèƒ½å·²é›†æˆ")
        if enable_visualization:
            print("ğŸ® æ§åˆ¶: Q=é€€å‡º, R=é‡ç½®, V=åˆ‡æ¢å¯è§†åŒ–")
        else:
            print("âš¡ æ— å¯è§†åŒ–æ¨¡å¼ - æœ€å¤§åŒ–æ€§èƒ½è¿è¡Œ")
            print("ğŸ® æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
        
        capture_thread = FrameCaptureThread(device, frame_queue)
        processing_thread = ProcessingThread(frame_queue, result_queue, stop_event, grpc_server, enable_visualization)

        capture_thread.start()
        processing_thread.start()
        print("ğŸ§µ å¤„ç†çº¿ç¨‹å·²å¯åŠ¨")

        if enable_visualization and result_queue is not None:
            # åˆ›å»ºå¯è§†åŒ–çª—å£
            window_name = 'OAKå•ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–ç‰ˆ'
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, 1280, 720)

            # å‡å°‘é¢„çƒ­æ—¶é—´ä»¥æé«˜å¯åŠ¨é€Ÿåº¦
            print("ğŸ“¸ ç›¸æœºé¢„çƒ­ä¸­...")
            for i in range(15):  # å‡å°‘åˆ°15å¸§
                try:
                    frame, _ = frame_queue.get(timeout=2)
                    text = f"WARMING UP... {i+1}/15"
                    cv2.putText(frame, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                    cv2.imshow(window_name, frame)
                    if cv2.waitKey(1) & 0xFF == ord("q"):
                        stop_event.set()
                        break
                except queue.Empty:
                    print("âš ï¸ é¢„çƒ­æœŸé—´æœªèƒ½ä»ç›¸æœºè·å–å¸§ã€‚")
                    break
            
            if not stop_event.is_set():
                print("âœ… é¢„çƒ­å®Œæˆï¼Œè¿›å…¥å•ç›®æ ‡è·Ÿè¸ªæ¨¡å¼")
                print("ğŸ’¡ ç­‰å¾…gRPCæŒ‡ä»¤é€‰æ‹©è·Ÿè¸ªç›®æ ‡...")

            # ä¸»å¯è§†åŒ–å¾ªç¯
            while not stop_event.is_set():
                try:
                    display_frame = result_queue.get(timeout=1)
                    cv2.imshow(window_name, display_frame)
                except queue.Empty:
                    # å¦‚æœå¤„ç†çº¿ç¨‹å¡ä½ï¼Œæ£€æŸ¥å®ƒæ˜¯å¦è¿˜æ´»ç€
                    if not processing_thread.is_alive():
                        print("âŒ å¤„ç†çº¿ç¨‹å·²æ„å¤–ç»ˆæ­¢ã€‚")
                        break
                    continue

                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    stop_event.set()
                elif key == ord('r'):
                    processing_thread.reset_tracker()
                    print("ğŸ”„ è·Ÿè¸ªå™¨å·²é‡ç½®")
                elif key == ord('v'):
                    visualization_status = processing_thread.toggle_visualization()
                    if not visualization_status:
                        cv2.destroyAllWindows()
                        print("ğŸ“º å¯è§†åŒ–å·²ç¦ç”¨ï¼Œåˆ‡æ¢åˆ°æ€§èƒ½æ¨¡å¼")
                        break  # é€€å‡ºå¯è§†åŒ–å¾ªç¯
                elif key == ord(' '):
                    print("â¸ï¸ å·²æš‚åœï¼ŒæŒ‰ä»»æ„é”®ç»§ç»­...")
                    cv2.waitKey(0)  # æš‚åœç›´åˆ°æŒ‰ä»»æ„é”®
            
            cv2.destroyAllWindows()
        else:
            # æ— å¯è§†åŒ–æ¨¡å¼ - æœ€å¤§åŒ–æ€§èƒ½
            print("âš¡ è¿›å…¥é«˜æ€§èƒ½æ— å¯è§†åŒ–æ¨¡å¼")
            try:
                while not stop_event.is_set():
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\nğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...")
                stop_event.set()

    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        stop_event.set()
    
    finally:
        print("æ­£åœ¨åœæ­¢çº¿ç¨‹...")
        stop_event.set()
        
        if capture_thread:
            capture_thread.stop()
            capture_thread.join(timeout=2)
        
        if processing_thread:
            processing_thread.join(timeout=5)

        # å…³é—­ç›¸æœºè¿æ¥
        camera_manager.close()
        
        print("\n===== æœ€ç»ˆè·Ÿè¸ªæŠ¥å‘Š =====")
        if processing_thread and processing_thread.target_manager:
            tm = processing_thread.target_manager
            print(f"æ€»è·Ÿè¸ªç›®æ ‡æ•°: {len(tm.targets)}")
            for target_id, target in tm.targets.items():
                status = "æ´»åŠ¨" if target.active else f"ä¸¢å¤±({target.lost_frame_count}å¸§)"
                if target.position:
                    print(f"ç›®æ ‡ ID {target_id}: {status}, æœ€åä½ç½®: ({target.position[0]:.1f}, {target.position[1]:.1f}), "
                          f"å§¿æ€ç½®ä¿¡åº¦: {target.pose_score:.2f}, "
                          f"é”å®šå¼ºåº¦: {target.lock_strength:.2f}")
                else:
                    print(f"ç›®æ ‡ ID {target_id}: {status}, æ— ä½ç½®ä¿¡æ¯")
            # ä¿å­˜æ‰€æœ‰ç‰¹å¾
            feature_storage.save_features()
        else:
            print("æœªèƒ½ç”ŸæˆæŠ¥å‘Šï¼Œå¤„ç†çº¿ç¨‹æœªæ­£å¸¸åˆå§‹åŒ–ã€‚")
    
    return True

if __name__ == "__main__":
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='OAKå•ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–ç‰ˆ (é›†æˆgRPCé€šä¿¡å’Œfast-reidåº“)')
    parser.add_argument('--grpc-server', default='localhost:50051', 
                       help='gRPCæœåŠ¡å™¨åœ°å€ (é»˜è®¤: localhost:50051)')
    parser.add_argument('--retries', type=int, default=3, 
                       help='ç¨‹åºå¯åŠ¨é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    parser.add_argument('--no-viz', '--no-visualization', action='store_true',
                       help='å¯ç”¨é«˜æ€§èƒ½æ¨¡å¼ï¼šç¦ç”¨å¯è§†åŒ–ç•Œé¢ï¼Œä»…è¿è¡Œåå°è·Ÿè¸ªå’ŒgRPCé€šä¿¡')
    parser.add_argument('--headless', action='store_true',
                       help='æ— å¤´æ¨¡å¼è¿è¡Œï¼ˆç­‰åŒäº --no-vizï¼Œæœ€å¤§åŒ–æ€§èƒ½ï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šå¯è§†åŒ–çŠ¶æ€
    enable_visualization = not (args.no_viz or args.headless)
    
    print(f"=== OAKå•ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿå¯åŠ¨ - æ€§èƒ½ä¼˜åŒ–ç‰ˆ (fast-reid) ===")
    print(f"gRPCæœåŠ¡å™¨: {args.grpc_server}")
    print(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {args.retries}")
    print(f"å¯è§†åŒ–æ¨¡å¼: {'å¯ç”¨' if enable_visualization else 'ç¦ç”¨ï¼ˆé«˜æ€§èƒ½æ¨¡å¼ï¼‰'}")

    
    # æ·»åŠ é‡è¯•æœºåˆ¶åˆ°ä¸»ç¨‹åº
    max_program_retries = args.retries
    for attempt in range(max_program_retries):
        print(f"\n========== ç¨‹åºå¯åŠ¨å°è¯• {attempt + 1}/{max_program_retries} ==========")
        
        try:
            if main(args.grpc_server, enable_visualization):
                print("ç¨‹åºæ­£å¸¸é€€å‡º")
                break
            else:
                print(f"ç¨‹åºå¯åŠ¨å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡)")
        except Exception as e:
            print(f"ç¨‹åºè¿è¡Œå¼‚å¸¸ (ç¬¬ {attempt + 1} æ¬¡): {e}")
        
        if attempt < max_program_retries - 1:
            print(f"ç­‰å¾…5ç§’åé‡è¯•...")
            time.sleep(5)
        else:
            print("æ‰€æœ‰å¯åŠ¨å°è¯•éƒ½å¤±è´¥äº†")
    
    sys.exit(0)

# echo 'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"' | sudo tee /etc/udev/rules.d/80-movidius.rules
# sudo udevadm control --reload-rules && sudo udevadm trigger